# Chapter 1: Introduction to Privacy for the IT Professional

This chapter establishes the foundational concepts of privacy for information technology professionals, distinguishing between security and privacy, outlining key privacy definitions, and introducing frameworks for managing data throughout its life cycle.

### 1.2 What Is Privacy?
The text describes privacy as "pluralistic," meaning it encompasses multiple definitions and dimensions rather than a single concept. The chapter highlights four prominent viewpoints used to define privacy:
* **Alan Westin’s Four States of Privacy:**
    * *Solitude:* Separation from the group; freedom from observation.
    * *Intimacy:* Acting as part of a small unit; negotiating secrecy rules.
    * *Anonymity:* Freedom from identification and surveillance in public.
    * *Reserve:* Psychological barrier against unwanted intrusion; the ability to withhold communication.
* **Helen Nissenbaum’s Contextual Integrity:** Privacy is defined by norms governing information flow within specific contexts (e.g., medical data is governed by different norms than banking data).
* **Daniel Solove’s Taxonomy of Privacy:** Focuses on specific activities that violate privacy, such as surveillance, interrogation, aggregation, and secondary use.
* **Ryan Calo’s Harm Dimensions:** Distinguishes between *objective harms* (measurable, observable violations) and *subjective harms* (the perception of unwanted observation or expectation of harm).

### 1.3 What Are Privacy Risks?
Privacy risk is defined as the likelihood that a threat will exploit a vulnerability combined with the resulting impact.
* **Threat Agents:** Can be internal (malicious insiders, careless employees) or external (hackers).
* **Common Threats:** Identity theft, lost or stolen unencrypted devices, and social engineering attacks like "phishing" or "spear-phishing."
* **Impact:** Costs include financial loss (e.g., identity fraud costs), reputation damage, system downtime, and loss of customer trust.

### 1.4 Security, Privacy, and Data Governance
The chapter clarifies that while security supports privacy, they are not equivalent.
* **Security:** Traditionally focuses on the "CIA triad": Confidentiality, Integrity, and Availability.
* **Privacy:** Broader than security. It involves individual autonomy, control over the granularity of information, and freedom from intrusion (e.g., surveillance or exposure).
* **Governance:** Effective privacy requires coordination between IT (CISO), Privacy Officers (CPO), and Legal departments. Data governance policies often stem from regulations like HIPAA, SOX, or GDPR.

### 1.5 Privacy Principles and Standards
IT professionals should use established principles to guide system design. The text details the **OECD Guidelines (1980)** as a foundational standard:
1.  **Collection Limitation:** Data should be obtained lawfully and with consent.
2.  **Data Quality:** Data must be relevant, accurate, complete, and up-to-date.
3.  **Purpose Specification:** Purposes for data collection must be specified at the time of collection.
4.  **Use Limitation:** Data should not be disclosed or used for other purposes without consent or legal authority.
5.  **Security Safeguards:** Reasonable safeguards must be in place against loss, access, or destruction.
6.  **Openness:** Policies regarding data should be transparent.
7.  **Individual Participation:** Individuals have rights to confirm, access, and challenge data held about them.
8.  **Accountability:** Data controllers are accountable for complying with these principles.

### 1.6 The Data Life Cycle
A framework for managing data flow to ensure end-to-end privacy protection:
* **Collection:** Can be active (subject aware) or passive (subject unaware). Includes first-party, third-party, and surveillance collection.
* **Consent:** Mechanisms include "Explicit" (checkboxes, buttons) and "Implicit" (policy links).
* **Processing & Disclosure:** Ensuring data is used only for stated purposes. "Repurposing" data creates significant privacy risks.
* **Retention:** Data should be retained only as long as necessary for business or legal needs.
* **Destruction:** Proper sanitization of media (overwriting, degaussing, incinerating) when data is no longer needed.

The chapter contrasts two organizational cultures regarding this cycle:
* **Maximize Information Utility:** Collects everything, retains indefinitely, and shares broadly to drive innovation.
* **Minimize Privacy Risk:** Collects only what is needed, retains only for the transaction, and strictly limits disclosure.

***

### 2.1.1 The Privacy Engineer

* **Role and Background**
    * **Function:** Serves as both an active member of project teams and a repository of knowledge for interacting with various stakeholders in the software ecosystem.
    * **Typical Career Path:** Often begins as a software developer, advances to a software project manager, and then transitions into the role of a privacy engineer.

* **Key Responsibilities**
    * **Requirements Collection:** Gathers critical regulatory requirements from legal teams to ensure marketing and other project requirements align with laws and social norms.
    * **Requirement Proposal:** Proposes additional privacy-related requirements specific to the project's needs.
    * **Design Collaboration:** Works with designers to discuss best practices and assess potential solutions, including the use of privacy-enhancing technologies (PETs) during the translation of requirements into design specifications.
    * **Verification:** Helps verify that design specifications are correctly implemented and achieve the intended privacy-related effects.
    * **Post-Deployment Support:** Assists with support after deployment, including addressing privacy-related bug fixes and enhancements.
    * **Monitoring and Feedback:** Collects user feedback and monitors external sources (blogs, mailing lists, news) for new privacy incidents to update relevant practices.

* **Community of Practice**
    * **Definition:** The privacy engineer develops a "community of practice," defined as a collective learning process focused on a shared enterprise (e.g., reducing privacy risks in technology).
    * **External Engagement:** This community includes professionals outside the engineer's own organization, such as bloggers, privacy law scholars, and nonprofits.
    * **Sources of Information:**
        * **Scholars & Nonprofits:** Monitoring thought leaders (e.g., Ryan Calo on autonomous vehicles) and organizations (e.g., Center for Democracy and Technology) for policy research on topics like location tracking and identity management.
        * **Regulators:** Tracking guidelines from bodies like the Federal Trade Commission (FTC), including case highlights and workshop summaries, to understand consensus on emerging privacy issues.
        * **Professional Associations:** Participating in workshops and training from organizations like the IAPP to network and improve professional practices.
    * **Goal:** To stay current on how privacy evolves with technology and to provide relevant, updated input into the organization's engineering processes.

* **Ethical Engineering Practice**
    * **Guidance Sources:** Communities of practice serve as a source for ethical guidance.
    * **Ethical Codes:** Privacy engineers rely on codes of ethics from major professional societies, including:
        * Association for Computing Machinery (ACM)
        * Institute of Electrical and Electronics Engineers (IEEE)
        * British Computer Society (BCS)
        * International Council on Systems Engineering (INCOSE)
    * **Evolution of Ethics:** While historical codes focused on professional conduct, modern codes emphasize the ethical obligation to address system privacy and security within complex sociotechnical environments.

### 2.1.3 Software Process Models

* **Origins and Purpose**
    * **Origin:** The concept of software engineering emerged from the 1968 NATO conference (Garmisch report) to manage engineering complexity.
    * **Goal:** To coordinate the construction of software, moving from personal projects to large-scale endeavors requiring sophisticated ecosystems and processes.

* **Core Software Development Activities**
    * Regardless of the specific process model used, six key activities are universally addressed:
        * **Requirements Engineering:** Identifying system constraints, stakeholder goals, and functional/behavioral properties (including privacy).
        * **Design:** Creating architectures that define how the system operates, including modular components and data flows.
        * **Implementation:** Translating design into source code and developing setup/configuration processes.
        * **Testing:** Verifying the system conforms to requirements through test cases and user testing (finding ways to "break" the system).
        * **Deployment:** Installing, configuring, and training users in the operational environment.
        * **Maintenance:** Updating software to fix bugs or add functionality post-deployment.

* **Types of Process Models**
    * **Plan-Driven Methods (e.g., Waterfall, Spiral):**
        * **Characteristics:** Emphasize up-front documentation and planning.
        * **Privacy Integration:** Privacy must be addressed early (CONOPS and requirements phase). Retrofitting privacy later is costly.
        * **Spiral Model:** Focuses on risk analysis. Iterative development where the team reassesses risks (feasibility, design alternatives) at each stage.
    * **Agile Methods (e.g., Extreme Programming, Scrum):**
        * **Characteristics:** Emphasize personal communication and small, dynamic teams.
        * **Scrum:** Uses timeboxing (sprints) and manages requirements via a "product backlog" of user stories.
        * **Privacy Integration:** Privacy engineers participate in developing user stories to identify risks. They review sprint backlogs to catch privacy dependencies (e.g., ensuring parental consent mechanisms are built before collecting child data).

* **DevOps and DevSecOps**
    * **DevOps:**
        * Integrates development and operations to speed up deployment.
        * Visualized as a figure eight; emphasizes continuous feedback and automation.
        * **Challenge:** High velocity can make ensuring privacy and security difficult.
    * **DevSecOps:**
        * Evolution of DevOps that integrates security throughout the lifecycle using automated tools (scanning, patching, testing).
        * **Note:** Privacy (beyond basic confidentiality) is not yet similarly integrated into this model.

* **Privacy Engineering Frameworks**
    * **Holistic Lifecycles:** Methods that act as specialized lifecycles themselves.
        * *OASIS Privacy Management Reference Model and Methodology (PMRM)*
        * *PRIPARE (Privacy and security-by-design)*
    * **Atomic Methods:** Aimed at specific engineering activities.
        * *LINDDUN:* A threat modeling method (discussed further in section 2.2.1.1).
        * *NIST Privacy Risk Assessment Methodology (PRAM):* For risk assessment (discussed further in section 2.2.2.3).
    * **Selection:** The choice of method depends on system complexity, environmental context, and organizational standards.

### 2.1.4 Defect, Fault, Error, Failure, and Harm

* **The Chain of Causality (IEEE Definitions)**
    * **Defect:** A flaw in the requirements, design, or implementation (e.g., coding mistake) that can cause a fault.
    * **Fault:** An incorrect step, process, or data definition within the computer program itself.
    * **Error:** The discrepancy between a computed/observed condition and the correct, specified condition.
    * **Failure:** The system's inability to perform its required function within the specified requirements.
    * **Harm:** The actual or potential negative impact ("hazard") on an individual's privacy.

* **Example Scenario: Unauthorized Disclosure of PII**
    * **Defect:** Source code that fails to correctly check for authorization.
    * **Fault:** The execution of that specific line of flawed code.
    * **Error:** The internal system state where unauthorized access is granted (deviating from the correct state of "access denied").
    * **Failure:** The external event where sensitive PII is actually disclosed to a third party.

* **Types of Privacy Harm**
    * **Objective Harm:** The unanticipated or coerced use of information against a person (measurable/observable).
    * **Subjective Harm:** The perception of unwanted observation (fear/discomfort), regardless of whether it actually occurs.

* **Daniel Solove’s Taxonomy of Privacy Problems**
    Solove categorizes privacy harms into four distinct risk categories:
    1.  **Information Collection:** (e.g., surveillance, interrogation).
    2.  **Information Processing:** (e.g., aggregation, identification, secondary use).
    3.  **Information Dissemination:** (e.g., breach of confidentiality, exposure).
    4.  **Invasion:** (e.g., intrusion, decisional interference).

* **The Engineer's Role**
    * Public reports usually focus on the **Failure** or **Harm** (the outcome).
    * Engineers must investigate to find the underlying **Errors, Faults, and Defects** (the root causes).
    * Engineers can use regulatory enforcement actions and news reports to identify these underlying technical causes and prevent similar privacy violations in their own systems.

### 2.1.5 Relevant Frameworks

* **Purpose and Usage**
    * Frameworks act as a collective resource for privacy engineers, covering requirements, design, controls, skills, and ethics.
    * Organizations typically leverage multiple frameworks rather than relying on just one, as different frameworks align with different aspects of practice.

* **Requirement and Control Frameworks**
    * **Generally Accepted Privacy Principles (GAPP):** Developed by CPA Canada and the AICPA. It serves as a source of general privacy requirements and includes a maturity model for detailed criteria.
    * **NIST Privacy Framework:** Breakdowns privacy risk management into five core activities: Identify, Govern, Control, Communicate, and Protect. These categories function as high-level requirements.
    * **NIST Special Publication 800-53 (Revision 5):** A comprehensive catalog of security and privacy controls. While intended for U.S. federal systems, it is widely used by non-government organizations for its detail and assessment guidance.
    * **ISO/IEC 27701:** An extension of the ISO/IEC 27001 security standard. It details controls specifically for Privacy Information Management Systems (PIMS).
    * **ISO/IEC 27550:** Addresses the relationship between privacy engineering and other engineering disciplines (like systems and security engineering) and common life cycle processes.

* **Privacy by Design (PbD) Standards**
    * **ISO 31700:** A standard addressing Privacy by Design for consumer goods and services, containing 30 high-level requirements.
    * **Institute of Operational Privacy Design (IOPD) Design Process Standard:** Specifies process requirements for integrating privacy into products and services across the entire life cycle.

* **Workforce and Skills**
    * **NIST NICE Framework (SP 800-181):** Provides a standard structure for defining cybersecurity and privacy roles and the necessary competencies.
    * **Privacy Workforce Taxonomy:** An initiative by NIST to align workforce definitions with the NIST Privacy Framework.

* **Ethical Frameworks**
    * **Professional Codes:** Ethical codes from societies like the ACM serve as frameworks for ethical engineering practice.
    * **ACM Code of Ethics:** Includes principles with direct implications for privacy engineering, such as "Respect Privacy" (Principle 1.6) and "Avoid Harm" (Principle 1.2), which help inform design trade-offs.
### 2.2 Privacy Risk Management

* **Overview**
    * Risk management is integral to developing reliable systems.
    * IT development involves **programmatic risk** (cost/schedule) and **technical risk** (technology specifics).
    * IT professionals often perform the role of a **privacy risk analyst**.

* **Definition of Risk**
    * **Classic Equation:** Risk = (Probability of an adverse event) × (Impact of the event).
    * **Numerical Measurement:**
        * Uses specific numbers for probability and impact to compute a comparable score.
        * **Challenge:** Often lacks the necessary empirical data or technical basis to be accurate.
    * **Ordinal Measurement:**
        * Uses relative scales (e.g., Low, Medium, High).
        * **Limitations:** Subjective; relies on human perception/bias; cannot be used for standard arithmetic (e.g., Low + High ≠ Medium).
    * **Quantitative Argument:** Authors like Hubbard, Seiersen, Freund, and Jones argue that quantitative measures are ascertainable and preferable to the imprecision of qualitative/ordinal measures.

* **Privacy Risk Scale (Bhatia and Breaux)**
    * An empirically validated scale based on the theory of perceived risk (Slovic).
    * **Method:** Surveys data subjects on their willingness to share data based on social/physical distance to a privacy harm.
    * **Scoring:** Measurements are multiplicative (e.g., a score of 4 is twice as risky as 2).
    * **Findings:**
        * "Induced disclosure" is perceived as lower risk than "surveillance" and "insecurity."
        * Higher perceived benefits lead to lower perceived risk (consistent with the Privacy Paradox).
        * Likelihood was not found to be a multiplicative factor in computing privacy risk for data subjects.

* **Risk Model Components**
    * Effective management requires a risk model that aligns three elements:
        1.  **Threats**
        2.  **Vulnerabilities** (exploited by threats)
        3.  **Risks** (Adverse Events with likelihood and impact)

* **Risk Management Framework**
    * A step-by-step process for applying the risk model to identify and manage risks.

* **Risk Management Options**
    * **Accept:** Acknowledge the risk but take no action (suitable for low risks or when fixing is too costly).
    * **Transfer:** Shift responsibility to another entity (e.g., purchasing cyber insurance, using third-party vendors).
    * **Mitigate:** Implement controls or design changes to reduce likelihood or impact (e.g., using encryption to mitigate the risk of device theft).
    * **Avoid:** Stop the activity, data collection, or system functionality that causes the risk. (Note: This is often difficult or impossible for essential functions).
    * **Risk-Risk Trade-off:** A situation where a decision to manage one risk inadvertently introduces a new, different risk.

### 2.2.1 Privacy Risk Modeling

* **Purpose**
    * To construct a comprehensive model that addresses **Threats**, **Vulnerabilities**, and **Consequences** (Adverse Events).
    * Each component (Threat, Vulnerability, Consequence) constitutes a model in itself.

* **Modeling Approaches**
    * **System-Specific:** Developing a custom model from scratch tailored to the specific system.
    * **Preexisting Models:** Using established, off-the-shelf models (e.g., LINDDUN, Solove’s Taxonomy).
    * **Hybrid:** Using a preexisting model as a baseline and tailoring it to fit the specific system context.

* **Execution Strategy**
    * Analysts frequently start with a **Consequence Model** (Adverse Events) because it connects directly to impact.
    * From the consequence, analysts work backward to identify the relevant vulnerabilities and threats.
    * **Warning:** Relying solely on consequence models can lead to an abbreviated analysis that misses the root causes (threats/vulnerabilities).

* **Available Component Models**
    * **Consequence Models:** Compliance Model, Fair Information Practice Principles (FIPPs), Subjective/Objective Dichotomy (Calo), Taxonomy of Privacy Problems (Solove), NIST Problems for Individuals.
    * **Vulnerability Models:** Contextual Integrity (Nissenbaum), NIST Problematic Data Actions.
    * **Threat Models:** LINDDUN, MITRE PANOPTIC™.

### **LINDDUN**

**LINDDUN** is a privacy threat modeling framework developed by the DistriNet Research Unit at KU Leuven (Belgium). It is designed to help privacy engineers and developers identify and mitigate privacy threats in software architectures during the early design phases. It is analogous to the STRIDE framework used for security threat modeling but focuses specifically on privacy.

  * **Official Website:** [linddun.org](https://linddun.org/)
  * **Core Methodology:** Data Flow Diagram (DFD) analysis.

#### **The Acronym (Threat Categories)**

The framework is named after the seven privacy threat categories it identifies:

1.  **L - Linkability:** The ability to link two or more items of interest (e.g., packets, records, actions) to the same user, even if their identity is unknown.
2.  **I - Identifiability:** The ability to identify a data subject from a set of data items.
3.  **N - Non-repudiation:** The inability of a data subject to deny a claim (e.g., having performed an action or sent a message), which is often a security goal but a privacy threat (e.g., for whistleblowers).
4.  **D - Detectability:** The ability to distinguish whether an item of interest exists or not (e.g., determining if a person is in a sensitive database).
5.  **D - Disclosure of Information:** The exposure of information to entities who are not authorized to access it.
6.  **U - Unawareness:** The data subject is unaware of the collection, processing, storage, or sharing of their personal data (often related to lack of notice/consent).
7.  **N - Non-compliance:** The processing of data is not compliant with legislation, regulations, or internal policies.

#### **Methodology Variants**

LINDDUN offers different levels of depth to suit different teams:

  * **LINDDUN GO:** A lightweight, card-based brainstorming method designed for agile teams and quick assessments.
  * **LINDDUN PRO:** A rigorous, systematic approach that involves creating a Data Flow Diagram (DFD), mapping threats to every element (entities, processes, data stores, data flows), and documenting everything thoroughly.
  * **LINDDUN MAESTRO:** An advanced, model-based approach (currently in development/research) for automated analysis.

-----

### **MITRE PANOPTIC™**

**MITRE PANOPTIC™** (Pattern and Action Nomenclature Of Privacy Threats In Context) is a newer privacy threat taxonomy developed by MITRE. Unlike LINDDUN, which is model-centric (analyzing a system diagram), PANOPTIC is data-driven and empirically derived from analyzing hundreds of real-world privacy incidents. It is designed to be the privacy equivalent of **MITRE ATT\&CK®**, focusing on the "tactics and techniques" of privacy violations.

  * **Primary Resource:** [suspicious link removed]
  * **Reference Paper:** [USENIX SOUPS Poster/Abstract](https://www.usenix.org/conference/soups2024/presentation/katcher-poster)

#### **Core Components**

PANOPTIC creates a structured vocabulary for privacy threats by splitting them into two taxonomies: **Contextual Domains** (where/who) and **Privacy Activities** (what happened).

**1. Contextual Domains**
These describe the environment and nature of the data involved:

  * **Environment:** Where the event occurs (e.g., Digital, Physical).
  * **Distribution:** The flow of data (e.g., One-to-One, One-to-Many).
  * **Interaction:** The relationship between the user and the entity (e.g., User-initiated, Third-party observation).
  * **Engagement:** Involvement of specific populations (e.g., Vulnerable populations, Children).
  * **Data Type:** The specific category of data (e.g., Biometric, Financial, Location).

**2. Privacy Activities**
These describe the specific actions (or inactions) that constitute the threat:

  * **Notice & Consent:** Issues with transparency (e.g., Misleading notice, Conditioning access on consent).
  * **Collection:** How data is gathered (e.g., Surveillance, Interrogation).
  * **Identification:** Linking data to individuals (e.g., Fingerprinting, Re-identification).
  * **Manageability:** Issues with user control (e.g., Inability to delete, Inability to correct).
  * **Sharing:** Transferring data to others (e.g., Sale of data, Unintended exposure).
  * **Retention:** Keeping data longer than necessary.
  * **Deviations:** Using data for purposes other than originally stated (secondary use).

-----



### Reference
**Book Title:** An Introduction to Privacy for Technology Professionals
**Edition:** Second Edition
**Executive Editor:** Travis D. Breaux, CIPT
**Publisher:** International Association of Privacy Professionals (IAPP)
**Publication Year:** 2024
**ISBN:** 978-1-948771-84-9
